{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification using Machine Learning",
    "",
    "**Syed A. Haider**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Environment",
    "",
    "Import necessary libraries such as NumPy, Pandas, and Matplotlib's Pyplot for data manipulation and visualization. Additionally, import various tools from Scikit-Learn for model building and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries",
    "import numpy as np",
    "import matplotlib.pyplot as plt",
    "import pandas as pd",
    "from sklearn.linear_model import LogisticRegression",
    "from sklearn.tree import DecisionTreeClassifier",
    "from sklearn.ensemble import RandomForestClassifier",
    "from sklearn.neighbors import KNeighborsClassifier",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppress scientific notation in NumPy arrays for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data",
    "",
    "This project utilizes the MNIST dataset, a collection of handwritten digits (0-9) in image format. The goal is to build a model that can accurately identify the digit in an image based on its pixel values.",
    "",
    "The dataset consists of 28x28 black-and-white images, with each image represented by 784 pixel values ranging from 0 to 255. The pixel values are provided in CSV files, with each row representing a single image.",
    "",
    "Load the MNIST dataset from 'digit-recognizer/train.csv' into a Pandas DataFrame, shuffle the data for randomness, and display the first few rows for initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and shuffle the MNIST dataset",
    "dr_train = pd.read_csv('train.csv')",
    "dr_train = dr_train.sample(frac=1, random_state=1)",
    "print(dr_train.shape)",
    "dr_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize computational resources, a subset of 10,000 observations is used for hyperparameter tuning and model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 10,000 observations for efficiency",
    "df_sample = dr_train.sample(n=10000, random_state=1)",
    "df_sample.shape",
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature and label arrays (X_sample, y_sample) from the sampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature and label arrays",
    "X_sample = df_sample.drop(['label'], axis=1).values",
    "y_sample = df_sample.label.values",
    "",
    "print(X_sample.shape, y_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a sample of the digits to gain a better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample of digits",
    "for i in range(8):",
    "    plt.subplot(2, 4, i + 1)",
    "    digit = X_sample[i, :].reshape(28, 28)",
    "    plt.imshow(digit, cmap='Greys')",
    "    plt.axis('off')",
    "plt.show()",
    "",
    "print(y_sample[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the pixel values to a range between 0 and 1 to improve the performance of some algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale pixel values",
    "X_scaled = X_sample / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection",
    "",
    "In this section, various machine learning models are evaluated and compared to select the best-performing model for MNIST digit classification. The models considered include Logistic Regression, K-Nearest Neighbors, Decision Tree, and Random Forest. ",
    "",
    "5-fold cross-validation is used throughout this section for model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression",
    "",
    "Evaluate the performance of a Logistic Regression model using 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Logistic Regression model",
    "lr_model = LogisticRegression(penalty='none', solver='saga', tol=0.01, max_iter=1000)",
    "cv = cross_val_score(lr_model, X_scaled, y_sample, cv=5, scoring='accuracy', n_jobs=-1)",
    "",
    "print('CV_score:', cv.round(4), cv.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors",
    "",
    "Perform hyperparameter tuning for a K-Nearest Neighbors model using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for KNN",
    "KNN = KNeighborsClassifier()",
    "neighbors_dict = {'n_neighbors': [2, 4, 6, 8, 10, 12, 14, 16]}",
    "",
    "knn_grid = GridSearchCV(KNN, neighbors_dict, cv=5, refit='True')",
    "knn_grid.fit(X_scaled, y_sample)",
    "knn_mod = knn_grid.best_estimator_",
    "",
    "print('Best Parameters:', knn_grid.best_params_)",
    "print('Best CV Score:', knn_grid.best_score_)",
    "print('Training Acc:', knn_grid.score(X_scaled, y_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of the KNN hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize KNN grid search results",
    "knn_summary = pd.DataFrame(knn_grid.cv_results_['params'])",
    "knn_summary['cv_score'] = knn_grid.cv_results_['mean_test_score']",
    "",
    "plt.plot(knn_summary.n_neighbors, knn_summary.cv_score)",
    "plt.xlabel('n_neighbors')",
    "plt.ylabel('CV Score')",
    "plt.xticks(knn_summary.n_neighbors)",
    "plt.grid()",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees",
    "",
    "Perform hyperparameter tuning for a Decision Tree model using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Decision Tree",
    "dt_clf = DecisionTreeClassifier(random_state=1)",
    "dt_parameters = {'max_depth': [8, 10, 12, 14, 16, 18, 20, 22, 24, 26],",
    "                  'min_samples_leaf': [2, 4, 6, 8, 10]}",
    "",
    "dt_grid = GridSearchCV(dt_clf, dt_parameters, cv=5, refit='True', n_jobs=-1)",
    "dt_grid.fit(X_scaled, y_sample)",
    "dt_mod = dt_grid.best_estimator_",
    "",
    "print('Best Parameters:', dt_grid.best_params_)",
    "print('Best CV Score:', round(dt_grid.best_score_, 4))",
    "print('Training Acc:', dt_grid.score(X_scaled, y_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of the Decision Tree hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Decision Tree grid search results",
    "dt_summary = pd.DataFrame(dt_grid.cv_results_['params'])",
    "dt_summary['cv_score'] = dt_grid.cv_results_['mean_test_score']",
    "",
    "for ms in dt_parameters['min_samples_leaf']:",
    "    temp = dt_summary.query(f'min_samples_leaf == {ms}')",
    "    plt.plot(temp.max_depth, temp.cv_score, label=ms)",
    "plt.xlabel('Maximum Depth')",
    "plt.ylabel('CV Score')",
    "plt.legend(title='Min Samples', bbox_to_anchor=[1, 1])",
    "plt.xticks(dt_parameters['max_depth'])",
    "plt.grid()",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests",
    "",
    "Perform hyperparameter tuning for a Random Forest model using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Random Forest",
    "rf_clf = RandomForestClassifier(random_state=1)",
    "rf_parameters = {'max_depth': [4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26],",
    "                  'min_samples_leaf': [2, 4, 6, 8, 10]}",
    "",
    "rf_grid = GridSearchCV(rf_clf, rf_parameters, cv=5, refit='True', n_jobs=-1)",
    "rf_grid.fit(X_scaled, y_sample)",
    "rf_mod = rf_grid.best_estimator_",
    "",
    "print('Best Parameters:', rf_grid.best_params_)",
    "print('Best CV Score:', round(rf_grid.best_score_, 4))",
    "print('Training Acc:', rf_grid.score(X_scaled, y_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of the Random Forest hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Random Forest grid search results",
    "rf_summary = pd.DataFrame(rf_grid.cv_results_['params'])",
    "rf_summary['cv_score'] = rf_grid.cv_results_['mean_test_score']",
    "",
    "for ms in rf_parameters['min_samples_leaf']:",
    "    temp = rf_summary.query(f'min_samples_leaf == {ms}')",
    "    plt.plot(temp.max_depth, temp.cv_score, label=ms)",
    "plt.xlabel('Maximum Depth')",
    "plt.ylabel('CV Score')",
    "plt.legend(title='Min Samples', bbox_to_anchor=[1, 1])",
    "plt.xticks(rf_parameters['max_depth'])",
    "plt.grid()",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model",
    "",
    "Based on the cross-validation scores from the previous section, the Random Forest model exhibited the highest performance. This section focuses on training and evaluating the final Random Forest model using the entire dataset for improved accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the full dataset for model training by creating feature and label arrays and scaling the pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the full dataset",
    "X_train = dr_train.drop(['label'], axis=1).values",
    "X_train_scaled = X_train / 255",
    "y_train = dr_train.label.values",
    "",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the final Random Forest model using the best hyperparameter values identified during tuning. Evaluate the model's performance using 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the final model",
    "rf_clf = RandomForestClassifier(max_depth=20, min_samples_leaf=2, random_state=1)",
    "rf_clf.fit(X_train_scaled, y_train)",
    "cv = cross_val_score(rf_clf, X_train_scaled, y_train, cv=10, scoring='accuracy', n_jobs=-1)",
    "print('CV Score:', cv.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate out-of-sample predictions using 10-fold cross-validation and create a classification report to assess the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and classification report",
    "predictions = cross_val_predict(rf_clf, X_train_scaled, y_train, cv=10, n_jobs=-1)",
    "cm = confusion_matrix(y_train, predictions)",
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Misclassifications**",
    "",
    "The most common misclassification mode by the model was to classify the digit 4 as the digit 9. The second most common misclassification mode was to classify the digit 9 as the digit 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a detailed classification report to evaluate the model's performance for each digit class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report",
    "cr = classification_report(y_train, predictions, output_dict=True)",
    "df = pd.DataFrame(cr).T",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on New Observations",
    "",
    "This section utilizes the trained Random Forest model to generate predictions for new, unlabeled images from the 'digit-recognizer/test.csv' file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the new observations, sample a subset for prediction, and scale the pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare new observations",
    "df_new = pd.read_csv('test.csv')",
    "df_new = df_new.sample(n=16, random_state=4)",
    "X_new = df_new.values / 255",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the sampled new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize new observations",
    "for i in range(16):",
    "    plt.subplot(4, 4, i + 1)",
    "    digit = X_new[i, :].reshape(28, 28)",
    "    plt.imshow(digit, cmap='Greys')",
    "    plt.axis('off')",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and display predictions for the new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for new observations",
    "preds = rf_clf.predict(X_new).reshape(4, 4)",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Predictions on New Observations**",
    "",
    "The model generated an incorrect prediction for observation 6. This may be due to [insert your analysis here]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate class probability estimates for the new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate probability estimates",
    "preds = rf_clf.predict_proba(X_new)",
    "rounded_preds = preds.round(2)",
    "rounded_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the model's confidence in its predictions by identifying the largest probability value for each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine model confidence",
    "probs = np.max(rounded_preds, axis=1)",
    "maxprobs = np.vstack(probs)",
    "print('largest value stacked', '\\n', maxprobs)",
    "sort = np.sort(maxprobs, axis=None)",
    "print('sorted', sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#
